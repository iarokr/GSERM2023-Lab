{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGwNwDKEt8lG"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"./hsg_logo.png\">\n",
    "\n",
    "##  Lab 03 - Supervised Machine Learning: Naive Bayes - Assignments\n",
    "\n",
    "GSERM Summer School 2023, Deep Learning: Fundamentals and Applications, University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYpS4wEPt8lI"
   },
   "source": [
    "In the last lab, we saw an application of **supervised machine learning** by using the **Gaussian Naive-Bayes (GNB) classifier** to classify features derived from real-world **Iris flowers**. You learned how to train a model and to evaluate and interpret its results. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments. But before we do so let's start with a motivational video by OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI: \"Solving Rubik's Cube with a Robot Hand\"\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('x4O8pojMF0w', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Br5f8mEt8lK"
   },
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0Jnx-Ljt8lK"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybF-i5mQt8lL"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Understand how to set up a **notebook or \"pipeline\"** that solves a simple supervised classification task.\n",
    "> 2. Recognize the **data elements** needed to train and evaluate a supervised machine learning classifier. \n",
    "> 3. Understand how a generative Gaussian **Naive-Bayes (NB)** classifier can be trained and evaluated.\n",
    "> 4. Know how to use Python's sklearn library to **train** and **evaluate** arbitrary classifiers.\n",
    "> 5. Understand how to **evaluate** and **interpret** the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZaa0qAnt8lY"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yTCqemyt8la"
   },
   "source": [
    "Similarly to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. In this lab will use the `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` and the `Seaborn` library. Let's import the libraries by the execution of the statements below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "o3ShseCwt8lb",
    "outputId": "1254c7ff-5876-4508-8fde-5528e4d704f3"
   },
   "outputs": [],
   "source": [
    "# import the numpy, scipy and pandas data science library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import sklearn data and data pre-processing libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import sklearn naive.bayes classifier library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# import matplotlib data visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFnbcu4yt8le"
   },
   "source": [
    "Enable inline Jupyter notebook plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLbxWoZit8lf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsFqwDkYt8ln"
   },
   "source": [
    "Let's set the `Seaborn` plotting theme for all subsequent visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMH7Y9-Ht8lo"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9HtRmw-t8nJ"
   },
   "source": [
    "## 3. Gaussian Naive-Bayes (NB) Classification Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMSfpCPvt8l4"
   },
   "source": [
    "### 3.1 Iris Dataset Download and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cilrWTyMt8l6"
   },
   "source": [
    "The **Iris Dataset** is a classic and straightforward dataset often used as a \"Hello World\" example in multi-class classification. This data set consists of measurements taken from three different types of iris flowers (referred to as **Classes**),  namely the Iris Setosa, the Iris Versicolour and the Iris Virginica, and their respective measured petal and sepal length (referred to as **Features**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlF-VYuOt8l7"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: auto\" src=\"./iris_dataset.png\">\n",
    "\n",
    "(Source: http://www.lac.inpe.br/~rafael.santos/Docs/R/CAP394/WholeStory-Iris.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBHv_Rbrt8l8"
   },
   "source": [
    "In total, the dataset consists of **150 samples** (50 samples taken per class) as well as their corresponding **4 different measurements** taken for each sample. Please, find below the list of the individual measurements:\n",
    "\n",
    ">- `Sepal length (cm)`\n",
    ">- `Sepal width (cm)`\n",
    ">- `Petal length (cm)`\n",
    ">- `Petal width (cm)`\n",
    "\n",
    "Further details of the dataset can be obtained from the following puplication: *Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\"*\n",
    "\n",
    "Let's load the dataset and conduct a preliminary data assessment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CtBrJGut8l9"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AE2PbwClt8mB"
   },
   "source": [
    "Print and inspect the names of the four features contained in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "NzLzNDo8t8mF",
    "outputId": "e336addc-0032-4f19-c65b-83a4482bc4a5"
   },
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIvnl8Qct8mK"
   },
   "source": [
    "Determine and print the feature dimensionality of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tq6gZN-1t8mM",
    "outputId": "8c985d93-12bb-4b17-e45d-6f284cedb17a"
   },
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwiIRMR_t8mW"
   },
   "source": [
    "Determine and print the class label dimensionality of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tayVqRQOt8mX",
    "outputId": "1ec43974-51bb-4117-e0e9-de84b82676bc"
   },
   "outputs": [],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoQlbXs_t8md"
   },
   "source": [
    "Print and inspect the names of the three classes contained in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "R__ACqSct8me",
    "outputId": "f257226b-e22b-441c-db4a-50e47c9dad6c"
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwqoNt8gt8mh"
   },
   "source": [
    "Let's briefly envision how the feature information of the dataset is collected and presented in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCgJtdiot8mi"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"./feature_collection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rD3SBLxzt8mi"
   },
   "source": [
    "Let's inspect the top five feature rows of the Iris Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "kju1z4Cft8mk",
    "outputId": "cf9f8028-e60b-4acf-dfd1-c6b2aaed1ddd"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris.data, columns=iris.feature_names).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P62AsvZ8t8mr"
   },
   "source": [
    "Let's also inspect the top five class labels of the Iris Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "oNjr0a5Dt8ms",
    "outputId": "160bca1e-1408-4904-efec-04a3a8939d97"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris.target, columns=[\"class\"]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fxz--vVdt8mu"
   },
   "source": [
    "Let's now conduct a more in depth data assessment. Therefore, we plot the feature distributions of the Iris dataset according to their respective class memberships as well as the features pairwise relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWofkTgQt8mw"
   },
   "source": [
    "Pls. note that we use Python's **Seaborn** library to create such a plot referred to as **Pairplot**. The Seaborn library is a powerful data visualization library based on the Matplotlib. It provides a great interface for drawing informative statstical graphics (https://seaborn.pydata.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "JmfO2-yit8mx",
    "outputId": "6a2392f8-a12e-4360-a5a8-acdf6bc9970d"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# load the dataset also available in seaborn\n",
    "iris_plot = sns.load_dataset(\"iris\")\n",
    "\n",
    "# plot a pairplot of the distinct feature distributions\n",
    "sns.pairplot(iris_plot, diag_kind='hist', hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gaussian Naive Bayes Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 400px; height: auto\" src=\"./bayes_theorem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZ-KsINqt8qh"
   },
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train and evaluate the prediction accuracy of different train- vs. eval-data ratios.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change the ratio of the Iris training data vs. test data split to **30%/70%** (currently 70%/30%), fit a Gaussian Naive Bayes model using the `Scikit-Learn` (https://scikit-learn.org) library and compute the classification accuracy of the trained model on the held-out test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL_44Y-qt8qi"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# To complete the exercise you might want to complete the following subtasks:\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: set the evaluation fraction to 70%\n",
    "# ***************************************************\n",
    "eval_fraction_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: set a random seed\n",
    "# ***************************************************\n",
    "seed = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 3: conduct the 70% training and 30% evaluation split using the 'train_test_split' function\n",
    "# ***************************************************\n",
    "x_train_ex1, x_eval_ex1, y_train_ex1, y_eval_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 4: init the Gaussian Naive Bayes classifier using the 'GaussianNB' function\n",
    "# ***************************************************\n",
    "gnb_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 5: train the Gaussian Naive Bayes classifier using the 'fit' function\n",
    "# ***************************************************\n",
    "gnb_ex1.??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 6: predict the labels of the evaluation data set using the 'predict' function\n",
    "# ***************************************************\n",
    "y_pred_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 7: determine and print the accuracy score using the 'accuracy_score' function\n",
    "# ***************************************************\n",
    "print(\"Classification Accuracy: \", ???) # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 8: determine and print the number of mislabeled data points\n",
    "# ***************************************************\n",
    "print(\"Mislabeled points out of a total {} points: {}\".format(x_eval_ex1.shape[0], ???)) # <-- insert your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2: Train and evaluate the prediction accuracy of different train- vs. eval-data ratios.**\n",
    "\n",
    "> Now, repeat the experiment a second time using a **90%/10%** Iris train vs. test data split fraction. Next, fit again a Gaussian Naive Bayes model using the `Scikit-Learn` library and also compute the classification accuracy of the trained model on the held-out test data. What can be observed when comparing the results of exercise 1 and 2 in terms of classification accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# To complete the exercise you might want to complete the following subtasks:\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: set the evaluation fraction to 10%\n",
    "# ***************************************************\n",
    "eval_fraction_ex2 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: set a random seed\n",
    "# ***************************************************\n",
    "seed = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 3: conduct the 90% training and 10% evaluation split using the 'train_test_split' function\n",
    "# ***************************************************\n",
    "x_train_ex1, x_eval_ex1, y_train_ex1, y_eval_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 4: init the Gaussian Naive Bayes classifier using the 'GaussianNB' function\n",
    "# ***************************************************\n",
    "gnb_ex2 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 5: train the Gaussian Naive Bayes classifier using the 'fit' function\n",
    "# ***************************************************\n",
    "gnb_ex2.??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 6: predict the labels of the evaluation data set using the 'predict' function\n",
    "# ***************************************************\n",
    "y_pred_ex2 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 7: determine and print the accuracy score using the 'accuracy_score' function\n",
    "# ***************************************************\n",
    "print(\"Classification Accuracy: \", ???) # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Task 8: determine and print the number of mislabeled data points\n",
    "# ***************************************************\n",
    "print(\"Mislabeled points out of a total {} points: {}\".format(x_eval_ex1.shape[0], ???)) # <-- insert your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVDiTWD0t8qo"
   },
   "source": [
    "**Exercise 3: Calculate the true-positive as well as the false-positive rate of the Iris versicolor vs. virginica.**\n",
    "\n",
    "> Compute and visualize the confusion matrices of (1) the experiment exhibiting a 30%/70% ratio of training data vs. evaluation data and (2) the experiment exhibiting a 10%/90% ratio of training data vs. evaluation data. Similar to the guided lab session you might want to use the `confusion_matrix` function that comes with the `Scikit-Learn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv_p7Z_3t8qL"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 450px; height: auto\" src=\"./confusion_matrix.png\">\n",
    "\n",
    "(Source: https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v418nuq5t8qp"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: determine the prediction confusion matrix\n",
    "# ***************************************************\n",
    "confusion_matrix_ex1 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Note: the following code lines will plot the confusion matrix (no need to change them)\n",
    "# ***************************************************\n",
    "\n",
    "# init the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plot confusion matrix heatmap\n",
    "sns.heatmap(confusion_matrix_ex1.T, square=True, annot=True, fmt='d', cbar=False, cmap='BuGn_r', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "\n",
    "# add plot axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]')\n",
    "\n",
    "# add plot title\n",
    "plt.title('Gaussian Naive Bayes Confusion Matrix - 70/10 split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: determine the prediction confusion matrix\n",
    "# ***************************************************\n",
    "confusion_matrix_ex2 = ??? # <-- insert your solution here\n",
    "\n",
    "# ***************************************************\n",
    "# Note: the following code lines will plot the confusion matrix (no need to change them)\n",
    "# ***************************************************\n",
    "\n",
    "# init the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plot confusion matrix heatmap\n",
    "sns.heatmap(confusion_matrix_ex2.T, square=True, annot=True, fmt='d', cbar=False, cmap='BuGn_r', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "\n",
    "# add plot axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]')\n",
    "\n",
    "# add plot title\n",
    "plt.title('Gaussian Naive Bayes Confusion Matrix - 90/10 split');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eGwNwDKEt8lG",
    "D0Jnx-Ljt8lK",
    "CZaa0qAnt8lY",
    "mMSfpCPvt8l4",
    "n94u0rxat8su"
   ],
   "name": "lab_03a_exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
